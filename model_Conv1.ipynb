{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:08.828543Z",
     "iopub.status.busy": "2023-08-22T06:17:08.827414Z",
     "iopub.status.idle": "2023-08-22T06:17:08.900001Z",
     "shell.execute_reply": "2023-08-22T06:17:08.898856Z",
     "shell.execute_reply.started": "2023-08-22T06:17:08.828493Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:09.909338Z",
     "iopub.status.busy": "2023-08-22T06:17:09.908897Z",
     "iopub.status.idle": "2023-08-22T06:17:24.226172Z",
     "shell.execute_reply": "2023-08-22T06:17:24.225075Z",
     "shell.execute_reply.started": "2023-08-22T06:17:09.909295Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import utils as np_utils \n",
    "\n",
    "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout, GlobalAveragePooling1D\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:28.523094Z",
     "iopub.status.busy": "2023-08-22T06:17:28.522133Z",
     "iopub.status.idle": "2023-08-22T06:17:38.194648Z",
     "shell.execute_reply": "2023-08-22T06:17:38.193298Z",
     "shell.execute_reply.started": "2023-08-22T06:17:28.523055Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "df = pd.read_pickle(\"/kaggle/input/asrqw334/data_final_s2_300s_1000hz_RT1purie.pkl\") # index column을 0번째 줄로 정한다는 의미입니다. \n",
    "\n",
    "df['label'].value_counts()\n",
    "df_y=df['label']\n",
    "df_x=df.drop(['label'],axis=1)\n",
    "\n",
    "# StandardScaler 객체 생성\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 데이터에 스케일링 적용\n",
    "scaled_ecg_data = scaler.fit_transform(df_x)\n",
    "\n",
    "# 스케일링된 데이터를 DataFrame 형태로 변환\n",
    "scaled_ecg_data_df = pd.DataFrame(scaled_ecg_data, columns=df_x.columns)\n",
    "\n",
    "# 스케일링된 데이터의 첫 5행을 출력\n",
    "df = pd.concat([scaled_ecg_data_df, df_y], axis = 1) # 열 방향으로 합치기\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:40.314971Z",
     "iopub.status.busy": "2023-08-22T06:17:40.314575Z",
     "iopub.status.idle": "2023-08-22T06:17:40.780965Z",
     "shell.execute_reply": "2023-08-22T06:17:40.779816Z",
     "shell.execute_reply.started": "2023-08-22T06:17:40.314937Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_test를 분리합니다. \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, valid_df = train_test_split(df, test_size = 0.1, stratify = df['label'])\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:42.314093Z",
     "iopub.status.busy": "2023-08-22T06:17:42.313706Z",
     "iopub.status.idle": "2023-08-22T06:17:42.323376Z",
     "shell.execute_reply": "2023-08-22T06:17:42.321929Z",
     "shell.execute_reply.started": "2023-08-22T06:17:42.314062Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:43.358422Z",
     "iopub.status.busy": "2023-08-22T06:17:43.357996Z",
     "iopub.status.idle": "2023-08-22T06:17:43.390067Z",
     "shell.execute_reply": "2023-08-22T06:17:43.388754Z",
     "shell.execute_reply.started": "2023-08-22T06:17:43.358385Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "epochs = 100\n",
    "\n",
    "## 조심 \n",
    "patience = 30 # earlystop 할 때 조절하는 것 \n",
    "## 고정\n",
    "data_len = len(df.iloc[0]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:44.837171Z",
     "iopub.status.busy": "2023-08-22T06:17:44.836751Z",
     "iopub.status.idle": "2023-08-22T06:17:44.849742Z",
     "shell.execute_reply": "2023-08-22T06:17:44.848283Z",
     "shell.execute_reply.started": "2023-08-22T06:17:44.837136Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset, dataloader\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size = 32, train = False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.train = train\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return np.ceil(len(self.df) / self.batch_size).astype(int)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.train: # Reshuffle train on end of epoch\n",
    "            self.df = self.df.sample(frac=1.0).reset_index(drop=True)\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.df.iloc[idx*self.batch_size:(idx+1)*self.batch_size, :-1].values # batch_size, 30000\n",
    "        batch_y = self.df.iloc[idx*self.batch_size:(idx+1)*self.batch_size].label.values # batch_size, 1\n",
    "\n",
    "        X = np.zeros((batch_x.shape[0], data_len))\n",
    "        \n",
    "        # train -> augmentation O\n",
    "        if self.train:\n",
    "          for i in range(batch_x.shape[0]): # i = 0, 1, 2, ,,, , 31\n",
    "            X[i] = batch_x[i] + np.random.normal(0, 0.05, size = (data_len,)) \n",
    "        \n",
    "        # valid -> augmentation X\n",
    "        else:\n",
    "          X = batch_x\n",
    "\n",
    "        # X의 차원을 늘려줍니다. <- model 들어갈 때 error 뜸\n",
    "        X = tf.expand_dims(X,2)\n",
    "\n",
    "        return X, batch_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:49.713773Z",
     "iopub.status.busy": "2023-08-22T06:17:49.713368Z",
     "iopub.status.idle": "2023-08-22T06:17:55.636860Z",
     "shell.execute_reply": "2023-08-22T06:17:55.635672Z",
     "shell.execute_reply.started": "2023-08-22T06:17:49.713738Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = DataGenerator(train_df, batch_size = batch_size, train = False)\n",
    "valid_ds = DataGenerator(valid_df, batch_size = batch_size, train = False)\n",
    "\n",
    "for x_train, y_train in train_ds:\n",
    "  print(x_train.shape)\n",
    "  print(y_train.shape)\n",
    "  break\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:17:58.952046Z",
     "iopub.status.busy": "2023-08-22T06:17:58.951086Z",
     "iopub.status.idle": "2023-08-22T06:17:59.319191Z",
     "shell.execute_reply": "2023-08-22T06:17:59.318345Z",
     "shell.execute_reply.started": "2023-08-22T06:17:58.951996Z"
    }
   },
   "outputs": [],
   "source": [
    "def network_v3():\n",
    "\n",
    "    # 마지막 차원 추가해줌 위에서\n",
    "    x = Input(shape = (data_len, 1), name='inputs_cnn')\n",
    "\n",
    "    # Conv1D\n",
    "    y = Convolution1D(16, 55, activation = 'leaky_relu')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool1D(10)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "    \n",
    "    y = Convolution1D(32, 55, activation = 'leaky_relu')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool1D(10)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "\n",
    "    y = Convolution1D(64, 25, activation = 'leaky_relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool1D(5)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "\n",
    "    y = Convolution1D(128, 10, activation = 'leaky_relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool1D(5)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "\n",
    "    y = Convolution1D(256, 10, activation = 'leaky_relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool1D(5)(y)\n",
    "    y = Dropout(0.2)(y)\n",
    "\n",
    "    y = Convolution1D(512, 9, activation = 'leaky_relu')(y)\n",
    "\n",
    "    # GAP\n",
    "    y = GlobalAveragePooling1D()(y)\n",
    "\n",
    "    # Dense\n",
    "    y = Dense(32, activation='leaky_relu')(y)\n",
    "    \n",
    "    y = Dense(1, activation='sigmoid', name='main_output')(y) \n",
    "\n",
    "    # Model\n",
    "    model = Model(x, y)\n",
    "\n",
    "    # return\n",
    "    return model\n",
    "\n",
    "model = network_v3()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:18:00.397251Z",
     "iopub.status.busy": "2023-08-22T06:18:00.396790Z",
     "iopub.status.idle": "2023-08-22T06:18:00.424198Z",
     "shell.execute_reply": "2023-08-22T06:18:00.423286Z",
     "shell.execute_reply.started": "2023-08-22T06:18:00.397207Z"
    }
   },
   "outputs": [],
   "source": [
    "# compile\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss = loss, optimizer = optimizer, metrics = ['acc'])\n",
    "\n",
    "es = EarlyStopping(monitor = 'val_loss', patience = patience, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-22T06:18:03.747259Z",
     "iopub.status.busy": "2023-08-22T06:18:03.746144Z",
     "iopub.status.idle": "2023-08-22T06:28:53.287406Z",
     "shell.execute_reply": "2023-08-22T06:28:53.286288Z",
     "shell.execute_reply.started": "2023-08-22T06:18:03.747217Z"
    }
   },
   "outputs": [],
   "source": [
    "# history_v1 = model.fit(train_ds, epochs = epochs, validation_data = valid_ds, callbacks = [es])\n",
    "history_v1 = model.fit(train_ds, epochs = epochs, validation_data = valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T02:43:42.530684Z",
     "iopub.status.busy": "2023-08-21T02:43:42.530309Z",
     "iopub.status.idle": "2023-08-21T02:43:42.547710Z",
     "shell.execute_reply": "2023-08-21T02:43:42.546537Z",
     "shell.execute_reply.started": "2023-08-21T02:43:42.530652Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def show_lcurve(hists, titles, colors=[\"r\",\"g\",\"b\",\"k\"], size=(12,4), x_itv=1, lw=1):\n",
    "    plt.figure(figsize=size)\n",
    "    plt.style.use(\"seaborn-white\")\n",
    "    # loss \n",
    "    plt.subplot(121)\n",
    "    for i, hist in enumerate(hists):\n",
    "        loss = hist.history['loss']\n",
    "        val_loss = hist.history['val_loss']\n",
    "        epochs = range(1, 1+len(loss))\n",
    "        xbins = range(0, len(loss)+1, x_itv)\n",
    "        plt.plot(epochs, loss, lw=lw,linestyle=':', label=f'{titles[i]} train loss', c=colors[i])\n",
    "        plt.plot(epochs, val_loss, lw=lw,marker='.', label=f'{titles[i]} valid loss', c=colors[i])\n",
    "        plt.legend();plt.grid(True);plt.xticks(xbins)\n",
    "        plt.xlabel('Epochs');plt.ylabel('Loss')\n",
    "        x, y = epochs[-1], hist.history['loss'][-1]\n",
    "        plt.text(x, y, np.round(y,2), c=colors[i])\n",
    "        x, y = epochs[-1], hist.history['val_loss'][-1]\n",
    "        plt.text(x, y, np.round(y,2), c=colors[i])\n",
    "\n",
    "    # acc\n",
    "    plt.subplot(122)\n",
    "    for i, hist in enumerate(hists):\n",
    "        acc = hist.history['acc']\n",
    "        val_acc = hist.history['val_acc']\n",
    "        plt.plot(epochs, acc, linestyle=':', lw=lw,label=f'{titles[i]} train acc', c=colors[i])\n",
    "        plt.plot(epochs, val_acc, marker='.', lw=lw,label=f'{titles[i]} valid acc', c=colors[i])\n",
    "        plt.legend();plt.grid(True);plt.xticks(xbins)\n",
    "        plt.xlabel('Epochs');plt.ylabel('Acc')\n",
    "        x, y = epochs[-1], hist.history['acc'][-1]\n",
    "        plt.text(x, y, np.round(y,2), c=colors[i])\n",
    "        x, y = epochs[-1], hist.history['val_acc'][-1]\n",
    "        plt.text(x, y, np.round(y,2), c=colors[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T02:43:44.124787Z",
     "iopub.status.busy": "2023-08-21T02:43:44.124392Z",
     "iopub.status.idle": "2023-08-21T02:43:44.691800Z",
     "shell.execute_reply": "2023-08-21T02:43:44.690735Z",
     "shell.execute_reply.started": "2023-08-21T02:43:44.124755Z"
    }
   },
   "outputs": [],
   "source": [
    "show_lcurve([history_v1], [\"hist\"], size = (22, 5), x_itv = 10 ) # x_itv: epoch 몇번씩 볼 수 있는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
